{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento\n",
    "\n",
    "O objetivo de pré-processar os dados é **aprimorar** o desempenho dos modelos de ML. Assim, um modelo treinado com dados pré-processados deve ter desempenho no mínimo equivalente a um modelo treinado com dados crus.\n",
    "\n",
    "## Por que pré-processar os dados?\n",
    "\n",
    "Dados no mundo real vêm\n",
    "\n",
    "* incompletos\n",
    "\n",
    "  ```person.occupation=''```\n",
    "\n",
    "\n",
    "* ruidosos\n",
    "\n",
    "  ```person.salary=-10; person.age=999```\n",
    "  \n",
    "  esses dados também podem ser chamados de *outliers*: são pontos que estão muito distantes da distribuição geral dos dados e em geral indicam algum erro na coleta ou no registro do dado\n",
    "\n",
    "\n",
    "* inconsistentes\n",
    "\n",
    "   ```personA.grade=B; personB.grade=8```\n",
    "   \n",
    "   pode acontecer ao integrar bases de dados diferentes\n",
    "   \n",
    "\n",
    "E os modelos de ML são sensíveis a tudo isso.\n",
    "\n",
    "Além disso, lembrando que o problema de aprendizado é um problema de otimização, precisamos aplicar transormações nos dados de forma a facilitar a convergência dos otimizadores.\n",
    "\n",
    "\n",
    "## As duas principais etapas de pré-processamento dos dados são\n",
    "\n",
    "* limpeza: preenchimento de valores faltantes, remoção de *outliers*, resolução de inconsistências\n",
    "* transformação: adequação dos dados para serem usados pelos modelos de ML; inclui normalização, agregação, redução e extração de *features*\n",
    "\n",
    "Para a primeira etapa, limpeza, é necessário algum conhecimento sobre a natureza dos dados (por exemplo, saber que idade e data de nascimento são *features* equivalentes). Dependendo da natureza dos dados, é recomendável conversar com especialistas. Essa é uma etapa que parece simples mas costuma ser trabalhosa. Não deve ser menosprezada :)\n",
    "\n",
    "Aqui, vamos usar um dataset já limpo e focar na tarefa de **transformar os dados** de forma que possam ser adequadamente interpretados pelos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nosso dataset\n",
    "\n",
    "Vamos usar o dataset *Boston Housing Prices*, organizado pelo grupo de *Machine Learning* da *University of California Irvine* e disponível para baixar diretamente através do pacote `sklearn`.\n",
    "\n",
    "Importando os pacotes que serão usados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos a função `load_boston` do `sklearn` para carregar os dados e ver a descrição das variáveis, e depois o pacote `pandas` para facilitar a manipulação dos dados tabulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n",
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_boston()\n",
    "\n",
    "print(data.keys())\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "target = data.target\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uma pipeline de pré-processamento de dados básica deve incluir\n",
    "* tratamento de variáveis categóricas\n",
    "* normalização/scaling\n",
    "* seleção de *features*\n",
    "\n",
    "### Tratamento de variáveis categóricas\n",
    "Variáveis categóricas são variáveis discretizadas, que representam atributos qualitativos (por exemplo, raça) ou intervalos de atributos quantitativos (por exemplo, faixa etária).\n",
    "\n",
    "Ao incluir essas variáveis num modelo de ML, é importante evitar introduzir relações de ordem inexistentes. Por exemplo, se há uma variável faixa etária que recebe 0 para [0-10], 1 para [11-20], 2 para [21-30], e assim por diante, é razoável que existam relações do tipo $0<1<2$ embutidas nos dados. Por outro lado, se há uma variável raça que recebe 0 para branco, 1 para amarelo, 2 para preto e 3 para outro, é recomendável criar $n$ novas variáveis binárias, uma para cada valor possível, a fim de evitar a introdução de relações do tipo branco > amarelo > preto. Este procedimento é chamado de **one-hot encoding**.\n",
    "\n",
    "No nosso dataset, as seguintes variáveis são consideradas categóricas:\n",
    "* CHAS: variável binária; não precisa de tratamento\n",
    "* AGE: variável discretizada com 9 valores possíveis; podemos fazer one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.CHAS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  5.,  4.,  8.,  6.,  7., 24.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.RAD.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O one-hot encoding pode ser feito pelo `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>...</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RAD_1.0</th>\n",
       "      <th>RAD_2.0</th>\n",
       "      <th>RAD_3.0</th>\n",
       "      <th>RAD_4.0</th>\n",
       "      <th>RAD_5.0</th>\n",
       "      <th>RAD_6.0</th>\n",
       "      <th>RAD_7.0</th>\n",
       "      <th>RAD_8.0</th>\n",
       "      <th>RAD_24.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  ...  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0  ...   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0  ...   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0  ...   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0  ...   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0  ...   \n",
       "\n",
       "   LSTAT  RAD_1.0  RAD_2.0  RAD_3.0  RAD_4.0  RAD_5.0  RAD_6.0  RAD_7.0  \\\n",
       "0   4.98        1        0        0        0        0        0        0   \n",
       "1   9.14        0        1        0        0        0        0        0   \n",
       "2   4.03        0        1        0        0        0        0        0   \n",
       "3   2.94        0        0        1        0        0        0        0   \n",
       "4   5.33        0        0        1        0        0        0        0   \n",
       "\n",
       "   RAD_8.0  RAD_24.0  \n",
       "0        0         0  \n",
       "1        0         0  \n",
       "2        0         0  \n",
       "3        0         0  \n",
       "4        0         0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding com pandas\n",
    "rad_onehot = pd.get_dummies(df.RAD, prefix='RAD')\n",
    "df = pd.concat([df, rad_onehot], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização/scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É necessário para padronizar o valor das *features* quando elas estão em intervalos muito variados (por exemplo, idade e salário têm ordens de grandeza diferentes). Mantendo todas as *features* em intervalos de valores similares, a convergência dos modelos é acelerada e, em alguns casos, o desempenho final é melhorado.\n",
    "\n",
    "As duas principais formas de se normalizar os dados são:\n",
    "\n",
    "Min max scaling\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "\n",
    "Standard scaling\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "x_{scaled} = \\frac{x - \\mu}{\\sigma}\n",
    "\\end{align}\n",
    "$\n",
    "  \n",
    "Note que a normalização é feita para cada uma das *features*, ou seja, para cada coluna do vetor de *features* $X$.\n",
    "\n",
    "O `sklearn` fornece funções para ambos os casos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>...</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RAD_1.0</th>\n",
       "      <th>RAD_2.0</th>\n",
       "      <th>RAD_3.0</th>\n",
       "      <th>RAD_4.0</th>\n",
       "      <th>RAD_5.0</th>\n",
       "      <th>RAD_6.0</th>\n",
       "      <th>RAD_7.0</th>\n",
       "      <th>RAD_8.0</th>\n",
       "      <th>RAD_24.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.040544</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.391378</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.349167</td>\n",
       "      <td>0.521869</td>\n",
       "      <td>0.676364</td>\n",
       "      <td>0.242381</td>\n",
       "      <td>0.371713</td>\n",
       "      <td>0.422208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301409</td>\n",
       "      <td>0.039526</td>\n",
       "      <td>0.047431</td>\n",
       "      <td>0.075099</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.051383</td>\n",
       "      <td>0.033597</td>\n",
       "      <td>0.047431</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.096679</td>\n",
       "      <td>0.233225</td>\n",
       "      <td>0.251479</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.238431</td>\n",
       "      <td>0.134627</td>\n",
       "      <td>0.289896</td>\n",
       "      <td>0.191482</td>\n",
       "      <td>0.378576</td>\n",
       "      <td>0.321636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197049</td>\n",
       "      <td>0.195035</td>\n",
       "      <td>0.212769</td>\n",
       "      <td>0.263812</td>\n",
       "      <td>0.412879</td>\n",
       "      <td>0.419485</td>\n",
       "      <td>0.220997</td>\n",
       "      <td>0.180367</td>\n",
       "      <td>0.212769</td>\n",
       "      <td>0.439543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131687</td>\n",
       "      <td>0.445392</td>\n",
       "      <td>0.433831</td>\n",
       "      <td>0.088259</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.175573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.507281</td>\n",
       "      <td>0.768280</td>\n",
       "      <td>0.188949</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.272901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.041258</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.646628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.491770</td>\n",
       "      <td>0.586798</td>\n",
       "      <td>0.938980</td>\n",
       "      <td>0.369088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     0.040544    0.113636    0.391378    0.069170    0.349167    0.521869   \n",
       "std      0.096679    0.233225    0.251479    0.253994    0.238431    0.134627   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000851    0.000000    0.173387    0.000000    0.131687    0.445392   \n",
       "50%      0.002812    0.000000    0.338343    0.000000    0.314815    0.507281   \n",
       "75%      0.041258    0.125000    0.646628    0.000000    0.491770    0.586798   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX  ...       LSTAT  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  ...  506.000000   \n",
       "mean     0.676364    0.242381    0.371713    0.422208  ...    0.301409   \n",
       "std      0.289896    0.191482    0.378576    0.321636  ...    0.197049   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "25%      0.433831    0.088259    0.130435    0.175573  ...    0.144040   \n",
       "50%      0.768280    0.188949    0.173913    0.272901  ...    0.265728   \n",
       "75%      0.938980    0.369088    1.000000    0.914122  ...    0.420116   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "          RAD_1.0     RAD_2.0     RAD_3.0     RAD_4.0     RAD_5.0     RAD_6.0  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     0.039526    0.047431    0.075099    0.217391    0.227273    0.051383   \n",
       "std      0.195035    0.212769    0.263812    0.412879    0.419485    0.220997   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "          RAD_7.0     RAD_8.0    RAD_24.0  \n",
       "count  506.000000  506.000000  506.000000  \n",
       "mean     0.033597    0.047431    0.260870  \n",
       "std      0.180367    0.212769    0.439543  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "dff = df.copy()\n",
    "dff[dff.columns] = scaler.fit_transform(df.values)\n",
    "dff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>...</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RAD_1.0</th>\n",
       "      <th>RAD_2.0</th>\n",
       "      <th>RAD_3.0</th>\n",
       "      <th>RAD_4.0</th>\n",
       "      <th>RAD_5.0</th>\n",
       "      <th>RAD_6.0</th>\n",
       "      <th>RAD_7.0</th>\n",
       "      <th>RAD_8.0</th>\n",
       "      <th>RAD_24.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-8.513173e-17</td>\n",
       "      <td>3.306534e-16</td>\n",
       "      <td>2.804081e-16</td>\n",
       "      <td>-3.100287e-16</td>\n",
       "      <td>-8.071058e-16</td>\n",
       "      <td>-5.189086e-17</td>\n",
       "      <td>-2.650493e-16</td>\n",
       "      <td>8.293761e-17</td>\n",
       "      <td>1.514379e-15</td>\n",
       "      <td>-9.934960e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.595123e-16</td>\n",
       "      <td>6.354162e-16</td>\n",
       "      <td>-1.068974e-15</td>\n",
       "      <td>5.487486e-16</td>\n",
       "      <td>-1.534126e-15</td>\n",
       "      <td>3.304340e-16</td>\n",
       "      <td>3.081637e-16</td>\n",
       "      <td>5.910950e-16</td>\n",
       "      <td>-5.813312e-16</td>\n",
       "      <td>3.427649e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-4.197819e-01</td>\n",
       "      <td>-4.877224e-01</td>\n",
       "      <td>-1.557842e+00</td>\n",
       "      <td>-2.725986e-01</td>\n",
       "      <td>-1.465882e+00</td>\n",
       "      <td>-3.880249e+00</td>\n",
       "      <td>-2.335437e+00</td>\n",
       "      <td>-1.267069e+00</td>\n",
       "      <td>-9.828429e-01</td>\n",
       "      <td>-1.313990e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.531127e+00</td>\n",
       "      <td>-2.028602e-01</td>\n",
       "      <td>-2.231424e-01</td>\n",
       "      <td>-2.849501e-01</td>\n",
       "      <td>-5.270463e-01</td>\n",
       "      <td>-5.423261e-01</td>\n",
       "      <td>-2.327373e-01</td>\n",
       "      <td>-1.864533e-01</td>\n",
       "      <td>-2.231424e-01</td>\n",
       "      <td>-5.940885e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-4.109696e-01</td>\n",
       "      <td>-4.877224e-01</td>\n",
       "      <td>-8.676906e-01</td>\n",
       "      <td>-2.725986e-01</td>\n",
       "      <td>-9.130288e-01</td>\n",
       "      <td>-5.686303e-01</td>\n",
       "      <td>-8.374480e-01</td>\n",
       "      <td>-8.056878e-01</td>\n",
       "      <td>-6.379618e-01</td>\n",
       "      <td>-7.675760e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.994200e-01</td>\n",
       "      <td>-2.028602e-01</td>\n",
       "      <td>-2.231424e-01</td>\n",
       "      <td>-2.849501e-01</td>\n",
       "      <td>-5.270463e-01</td>\n",
       "      <td>-5.423261e-01</td>\n",
       "      <td>-2.327373e-01</td>\n",
       "      <td>-1.864533e-01</td>\n",
       "      <td>-2.231424e-01</td>\n",
       "      <td>-5.940885e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-3.906665e-01</td>\n",
       "      <td>-4.877224e-01</td>\n",
       "      <td>-2.110985e-01</td>\n",
       "      <td>-2.725986e-01</td>\n",
       "      <td>-1.442174e-01</td>\n",
       "      <td>-1.084655e-01</td>\n",
       "      <td>3.173816e-01</td>\n",
       "      <td>-2.793234e-01</td>\n",
       "      <td>-5.230014e-01</td>\n",
       "      <td>-4.646726e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.812536e-01</td>\n",
       "      <td>-2.028602e-01</td>\n",
       "      <td>-2.231424e-01</td>\n",
       "      <td>-2.849501e-01</td>\n",
       "      <td>-5.270463e-01</td>\n",
       "      <td>-5.423261e-01</td>\n",
       "      <td>-2.327373e-01</td>\n",
       "      <td>-1.864533e-01</td>\n",
       "      <td>-2.231424e-01</td>\n",
       "      <td>-5.940885e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.396560e-03</td>\n",
       "      <td>4.877224e-02</td>\n",
       "      <td>1.015999e+00</td>\n",
       "      <td>-2.725986e-01</td>\n",
       "      <td>5.986790e-01</td>\n",
       "      <td>4.827678e-01</td>\n",
       "      <td>9.067981e-01</td>\n",
       "      <td>6.623709e-01</td>\n",
       "      <td>1.661245e+00</td>\n",
       "      <td>1.530926e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.030188e-01</td>\n",
       "      <td>-2.028602e-01</td>\n",
       "      <td>-2.231424e-01</td>\n",
       "      <td>-2.849501e-01</td>\n",
       "      <td>-5.270463e-01</td>\n",
       "      <td>-5.423261e-01</td>\n",
       "      <td>-2.327373e-01</td>\n",
       "      <td>-1.864533e-01</td>\n",
       "      <td>-2.231424e-01</td>\n",
       "      <td>1.683251e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9.933931e+00</td>\n",
       "      <td>3.804234e+00</td>\n",
       "      <td>2.422565e+00</td>\n",
       "      <td>3.668398e+00</td>\n",
       "      <td>2.732346e+00</td>\n",
       "      <td>3.555044e+00</td>\n",
       "      <td>1.117494e+00</td>\n",
       "      <td>3.960518e+00</td>\n",
       "      <td>1.661245e+00</td>\n",
       "      <td>1.798194e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.548771e+00</td>\n",
       "      <td>4.929503e+00</td>\n",
       "      <td>4.481443e+00</td>\n",
       "      <td>3.509386e+00</td>\n",
       "      <td>1.897367e+00</td>\n",
       "      <td>1.843909e+00</td>\n",
       "      <td>4.296689e+00</td>\n",
       "      <td>5.363274e+00</td>\n",
       "      <td>4.481443e+00</td>\n",
       "      <td>1.683251e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CRIM            ZN         INDUS          CHAS           NOX  \\\n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean  -8.513173e-17  3.306534e-16  2.804081e-16 -3.100287e-16 -8.071058e-16   \n",
       "std    1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00   \n",
       "min   -4.197819e-01 -4.877224e-01 -1.557842e+00 -2.725986e-01 -1.465882e+00   \n",
       "25%   -4.109696e-01 -4.877224e-01 -8.676906e-01 -2.725986e-01 -9.130288e-01   \n",
       "50%   -3.906665e-01 -4.877224e-01 -2.110985e-01 -2.725986e-01 -1.442174e-01   \n",
       "75%    7.396560e-03  4.877224e-02  1.015999e+00 -2.725986e-01  5.986790e-01   \n",
       "max    9.933931e+00  3.804234e+00  2.422565e+00  3.668398e+00  2.732346e+00   \n",
       "\n",
       "                 RM           AGE           DIS           RAD           TAX  \\\n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean  -5.189086e-17 -2.650493e-16  8.293761e-17  1.514379e-15 -9.934960e-16   \n",
       "std    1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00   \n",
       "min   -3.880249e+00 -2.335437e+00 -1.267069e+00 -9.828429e-01 -1.313990e+00   \n",
       "25%   -5.686303e-01 -8.374480e-01 -8.056878e-01 -6.379618e-01 -7.675760e-01   \n",
       "50%   -1.084655e-01  3.173816e-01 -2.793234e-01 -5.230014e-01 -4.646726e-01   \n",
       "75%    4.827678e-01  9.067981e-01  6.623709e-01  1.661245e+00  1.530926e+00   \n",
       "max    3.555044e+00  1.117494e+00  3.960518e+00  1.661245e+00  1.798194e+00   \n",
       "\n",
       "       ...         LSTAT       RAD_1.0       RAD_2.0       RAD_3.0  \\\n",
       "count  ...  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean   ... -1.595123e-16  6.354162e-16 -1.068974e-15  5.487486e-16   \n",
       "std    ...  1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00   \n",
       "min    ... -1.531127e+00 -2.028602e-01 -2.231424e-01 -2.849501e-01   \n",
       "25%    ... -7.994200e-01 -2.028602e-01 -2.231424e-01 -2.849501e-01   \n",
       "50%    ... -1.812536e-01 -2.028602e-01 -2.231424e-01 -2.849501e-01   \n",
       "75%    ...  6.030188e-01 -2.028602e-01 -2.231424e-01 -2.849501e-01   \n",
       "max    ...  3.548771e+00  4.929503e+00  4.481443e+00  3.509386e+00   \n",
       "\n",
       "            RAD_4.0       RAD_5.0       RAD_6.0       RAD_7.0       RAD_8.0  \\\n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean  -1.534126e-15  3.304340e-16  3.081637e-16  5.910950e-16 -5.813312e-16   \n",
       "std    1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00   \n",
       "min   -5.270463e-01 -5.423261e-01 -2.327373e-01 -1.864533e-01 -2.231424e-01   \n",
       "25%   -5.270463e-01 -5.423261e-01 -2.327373e-01 -1.864533e-01 -2.231424e-01   \n",
       "50%   -5.270463e-01 -5.423261e-01 -2.327373e-01 -1.864533e-01 -2.231424e-01   \n",
       "75%   -5.270463e-01 -5.423261e-01 -2.327373e-01 -1.864533e-01 -2.231424e-01   \n",
       "max    1.897367e+00  1.843909e+00  4.296689e+00  5.363274e+00  4.481443e+00   \n",
       "\n",
       "           RAD_24.0  \n",
       "count  5.060000e+02  \n",
       "mean   3.427649e-15  \n",
       "std    1.000990e+00  \n",
       "min   -5.940885e-01  \n",
       "25%   -5.940885e-01  \n",
       "50%   -5.940885e-01  \n",
       "75%    1.683251e+00  \n",
       "max    1.683251e+00  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "dff = df.copy()\n",
    "dff[dff.columns] = scaler.fit_transform(df.values)\n",
    "dff.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de features\n",
    "\n",
    "Dado um dataset de *shape* $M x N$ (M amostras, N features), uma *rule of thumb* para um tamanho de dataset adequado é $M \\geq 10N$. Nosso dataset tem shape 506x13, de um tamanho adequado, então não é preciso selecionar *features*.\n",
    "\n",
    "Mas e se tivéssemos poucas amostras ou muitas *features*? Nesses casos, é necessário **extrair** ou **selecionar** *features* que contenham as informações mais relevantes.\n",
    "\n",
    "Uma forma de fazer isso é avaliar as correlações entre *features* e *target* e descartar *features* sejam menos correlacionadas com o *target*. O método `SelectKBest` do `sklearn` faz isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CRIM', 89.48611475768118),\n",
       " ('INDUS', 153.95488313610983),\n",
       " ('NOX', 112.59148027969944),\n",
       " ('RM', 471.84673987638683),\n",
       " ('AGE', 83.47745921923611),\n",
       " ('RAD', 85.91427766984044),\n",
       " ('TAX', 141.76135657742293),\n",
       " ('PTRATIO', 175.10554287569468),\n",
       " ('LSTAT', 601.6178711098955),\n",
       " ('RAD_24.0', 93.90104712598881)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = SelectKBest(score_func=f_regression, k=10)\n",
    "X_selected = fs.fit_transform(dff, target)\n",
    "\n",
    "cols = fs.get_support()\n",
    "names = dff.columns.values[cols]\n",
    "scores = fs.scores_[cols]\n",
    "names_scores = list(zip(names, scores))\n",
    "\n",
    "names_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E se os dados não forem tabulares?\n",
    "\n",
    "A extração de *features* é especialmente importante para dados com dimensão muito alta. Por exemplo, se tivermos imagens 32x32 e quisermos usar o valor de cada pixel como *feature*, teríamos 32x32 = 1024 *features*. Por isso, em campos como visão computacional e processamento de texto (NLP), são usados extratores de *features* especializados.\n",
    "\n",
    "Alguns dos extratores de *features* tradicionais para imagens são:\n",
    "* SURF\n",
    "* SIFT\n",
    "\n",
    "Alguns dos extratores de *features* tradicionais para texto são:\n",
    "* bag of words\n",
    "* TF-IDF\n",
    "\n",
    "*Deep learning* é uma forma de se extrair *features* automaticamente e aprender uma tarefa ao mesmo tempo. Veremos um pouco sobre isso na última aula."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
